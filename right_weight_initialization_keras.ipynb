{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Глубокие сети\" с 147\n",
    "Эксперемент: так ли хороша нормализованная инициализация\n",
    "Разница потрясающая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Классика из коробки\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перекодировка ответов\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перевод матриц в надлежащий вид\n",
    "x_train = x_train.reshape([-1, 28*28]) / 255.\n",
    "x_test = x_test.reshape([-1, 28*28]) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция создающая модель (различается лишь способ задания весов)\n",
    "def create_model(init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(28*28, ), kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dense(100, kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dense(100, kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dense(100, kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dense(10, kernel_initializer=init, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/banayaki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 202s 3ms/step - loss: 2.3009 - acc: 0.1119 - val_loss: 2.2988 - val_acc: 0.1135\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 2.2963 - acc: 0.1124 - val_loss: 2.2917 - val_acc: 0.1135\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 2.2635 - acc: 0.1734 - val_loss: 2.1390 - val_acc: 0.2279\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 1.7424 - acc: 0.3505 - val_loss: 1.2954 - val_acc: 0.5542\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 1.1606 - acc: 0.5913 - val_loss: 1.0497 - val_acc: 0.6464\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.9168 - acc: 0.7080 - val_loss: 0.7514 - val_acc: 0.7752\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.6781 - acc: 0.7981 - val_loss: 0.5980 - val_acc: 0.8268\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.5562 - acc: 0.8437 - val_loss: 0.5022 - val_acc: 0.8645\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.4653 - acc: 0.8739 - val_loss: 0.4184 - val_acc: 0.8887\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.3968 - acc: 0.8937 - val_loss: 0.3697 - val_acc: 0.9024\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3498 - acc: 0.9056 - val_loss: 0.3407 - val_acc: 0.9121\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3154 - acc: 0.9150 - val_loss: 0.3275 - val_acc: 0.9105\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2852 - acc: 0.9237 - val_loss: 0.2827 - val_acc: 0.9256\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2605 - acc: 0.9298 - val_loss: 0.2736 - val_acc: 0.9281\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2385 - acc: 0.9347 - val_loss: 0.2491 - val_acc: 0.9346\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2206 - acc: 0.9397 - val_loss: 0.2391 - val_acc: 0.9351\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2016 - acc: 0.9451 - val_loss: 0.2197 - val_acc: 0.9395\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1878 - acc: 0.9486 - val_loss: 0.2054 - val_acc: 0.9452\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1731 - acc: 0.9528 - val_loss: 0.1930 - val_acc: 0.9484\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1607 - acc: 0.9552 - val_loss: 0.1941 - val_acc: 0.9450\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1508 - acc: 0.9590 - val_loss: 0.1714 - val_acc: 0.9528\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1408 - acc: 0.9609 - val_loss: 0.1635 - val_acc: 0.9550\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1322 - acc: 0.9628 - val_loss: 0.1540 - val_acc: 0.9575\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1253 - acc: 0.9648 - val_loss: 0.1590 - val_acc: 0.9549\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1187 - acc: 0.9666 - val_loss: 0.1546 - val_acc: 0.9556\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1129 - acc: 0.9684 - val_loss: 0.1463 - val_acc: 0.9586\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1081 - acc: 0.9694 - val_loss: 0.1401 - val_acc: 0.9600\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1030 - acc: 0.9712 - val_loss: 0.1369 - val_acc: 0.9615\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0986 - acc: 0.9724 - val_loss: 0.1338 - val_acc: 0.9627\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0942 - acc: 0.9736 - val_loss: 0.1475 - val_acc: 0.9577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd1590dbf60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Собственно инициализация модели\n",
    "uniform_model = create_model(\"uniform\")\n",
    "uniform_model.compile(loss='categorical_crossentropy', optimizer='sgd',\n",
    "                     metrics=['accuracy'])\n",
    "uniform_model.fit(x_train, y_train, batch_size=64, nb_epoch=30,\n",
    "                 verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/banayaki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.7553 - acc: 0.8090 - val_loss: 0.3873 - val_acc: 0.8956\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3511 - acc: 0.9031 - val_loss: 0.3006 - val_acc: 0.9145\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2913 - acc: 0.9165 - val_loss: 0.2659 - val_acc: 0.9242\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2567 - acc: 0.9262 - val_loss: 0.2363 - val_acc: 0.9317\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2312 - acc: 0.9332 - val_loss: 0.2155 - val_acc: 0.9370\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2104 - acc: 0.9393 - val_loss: 0.2009 - val_acc: 0.9414\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1931 - acc: 0.9441 - val_loss: 0.1868 - val_acc: 0.9448\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1783 - acc: 0.9483 - val_loss: 0.1739 - val_acc: 0.9482\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1653 - acc: 0.9515 - val_loss: 0.1643 - val_acc: 0.9524\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1541 - acc: 0.9549 - val_loss: 0.1543 - val_acc: 0.9551\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1442 - acc: 0.9580 - val_loss: 0.1433 - val_acc: 0.9581\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1350 - acc: 0.9606 - val_loss: 0.1375 - val_acc: 0.9584\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1270 - acc: 0.9629 - val_loss: 0.1333 - val_acc: 0.9606\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1194 - acc: 0.9650 - val_loss: 0.1279 - val_acc: 0.9620\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1129 - acc: 0.9669 - val_loss: 0.1214 - val_acc: 0.9638\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1069 - acc: 0.9687 - val_loss: 0.1186 - val_acc: 0.9648\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1015 - acc: 0.9705 - val_loss: 0.1127 - val_acc: 0.9654\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0962 - acc: 0.9721 - val_loss: 0.1099 - val_acc: 0.9660\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0912 - acc: 0.9736 - val_loss: 0.1074 - val_acc: 0.9684\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0871 - acc: 0.9741 - val_loss: 0.1026 - val_acc: 0.9682\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0831 - acc: 0.9757 - val_loss: 0.1005 - val_acc: 0.9681\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0789 - acc: 0.9767 - val_loss: 0.0992 - val_acc: 0.9693\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0752 - acc: 0.9780 - val_loss: 0.0978 - val_acc: 0.9690\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0720 - acc: 0.9790 - val_loss: 0.0948 - val_acc: 0.9703\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0688 - acc: 0.9801 - val_loss: 0.0932 - val_acc: 0.9720\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0659 - acc: 0.9810 - val_loss: 0.0940 - val_acc: 0.9713\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0631 - acc: 0.9817 - val_loss: 0.0902 - val_acc: 0.9729\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0601 - acc: 0.9828 - val_loss: 0.0894 - val_acc: 0.9730\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0580 - acc: 0.9834 - val_loss: 0.0886 - val_acc: 0.9724\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0552 - acc: 0.9841 - val_loss: 0.0895 - val_acc: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd1565c1278>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glorot_model = create_model(\"glorot_normal\")\n",
    "glorot_model.compile(loss='categorical_crossentropy', optimizer='sgd',\n",
    "                    metrics=['accuracy'])\n",
    "glorot_model.fit(x_train, y_train, batch_size=64, nb_epoch=30,\n",
    "                verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

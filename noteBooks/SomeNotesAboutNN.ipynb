{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PassiveAggressiveClassifier,\n",
    "               <br>SGDClassifier,\n",
    "               <br>Perceptron+,\n",
    "               <br>DecisionTreeClassifier,\n",
    "               <br>RandomForestClassifier,\n",
    "               <br>LogisticRegression+,\n",
    "               <br>MLPClassifier,\n",
    "               <br>KNeighborsClassifier,\n",
    "               <br>SVC,\n",
    "               <br>GaussianNB,\n",
    "               <br>ExtraTreeClassifier,\n",
    "               <br>LinearSVC,\n",
    "               <br>GaussianProcessClassifier,\n",
    "<br>GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основы основ #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции активации ##\n",
    "<img src=\"ActivationFunc.png\">\n",
    "<br>Теперь кратко об их основых преимуществах. \n",
    "<br>Сигмоида. Преимуществ по сравнению с другими вариантами не так много. Старенькая функция активации.\n",
    "<br>Гиперболический тангенс. Чуть лучше чем сигмоида благодаря тому, что в нуле имеет более крутой наклон. В остальном все те же минусы: тяжело считать производную и не понимает 'силу активации'\n",
    "<br>Функция Хевисайда. Тут даже сказать нечего, производная равна нулю, значит и градиент равен нулю, все плохо.\n",
    "<br>Soft plus. Интеграл взятый от сигмоиды, т.к. сигмоида не учитывет слишком высокую силу активацию, решили найти бесконечный ряд из суммы сигмоид, в итоге получили функцию soft plus, лучше предыдующих вариантов тем, что реагирует на большие веса\n",
    "<br>ReLU (rectified linear units) - улучшенный линейный нейрон. Самый хороший вариант для просто нейронной сети. Является апроксимацией soft plus. Маленькие затраты на вычисление функции и градиента, что несомненно плюс, так же отличает сильную активацию от не очень сильной. \n",
    "<br>PReLU (parametrezied ReLU). Тут у нас появляется параметр, благодаря которому мы имеем немного другую производную при малых x. \n",
    "<br>Про ELU сказать особо нечего.\n",
    "\n",
    "<br>Так что вывод можно сделать такой. Для классификации удобно будет использовать ReLU для скрытых слоев и tanh(или сигмоиду) для выходного слоя, что бы определить вероятность принадлежности объекта тому или иному классу. А для задач регресии стоит применять какую-либо линейную функцию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Целевые функции (функции ошибок) ##\n",
    "\n",
    "#### Среднеквадратичная функция (MSE)\n",
    "$$ MSE = \\frac{1}{2}\\Sigma^{n}_{i = 1}(a_i - y_i)^2 $$\n",
    "Особенности:\n",
    "<li>Зависимость от производной функции активации\n",
    "    \n",
    "#### Перекрестная энтропия \n",
    "$$Cross-Entropy\\, loss: J = - \\frac{1}{n}\\Sigma_{i=1}^{n}\\Sigma_{j=1}^{m}\\Big(y_{j}^{(i)}\\ln a_{j}^{(i)} + (1 - y_{j}^{(i)})\\ln(1 - a_{j}^{(i)})\\Big) $$\n",
    "Особенности:\n",
    "<li>Высокая скорость сходимости алгоритма обучения\n",
    "\n",
    "$$ i - номер\\, эксперемента(испытания); j - номер\\, выхода $$\n",
    "\n",
    "#### Правдоподобие (Log-likelihood)\n",
    "$$ E = - \\ln a^L_i $$\n",
    "\n",
    "\n",
    "#### Выбор типа функции потерь\n",
    "\n",
    "###### Задача регрессии\n",
    "функция активации в выходном слое: линейная\n",
    "<br>функция потерь: MSE или Cross Entropy\n",
    "\n",
    "##### Задача классификации\n",
    "функция активации в выходном слое: сигмоида\n",
    "функция потерь: Cross Entropy или Правдоподобие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим функцию $f(x)$ и её производную $f'(x)$, которая определяет наклон $f(x)$ в точке $x$ (геометрический смысл производной). Знание производной - очень ползено для минимизации целевой функции, так мы можем изменять $f(x)$ двигаясь небольшыми шажками в сторону противоположенную знаку производной, т.е. $f(x - \\epsilon\\ sign(f'(x)))$ при небольших $\\epsilon$. Такой метод называется градиентным спуском. И он легко обобщается для функций многих переменных, для этого нужно воспользоваться понятием градиента. Градиент задает направление наискорейшего роста функции, поэтому мы воспользуемся $-\\nabla_x f(x)$. И тогда новая точка будет выбираться следующим уравнением: \n",
    "<br><br>\n",
    "$$x' = x - \\epsilon\\ \\nabla_x f(x)$$ \n",
    "<br>\n",
    "Критериями останова такого метода могут быть:\n",
    "<ol>\n",
    "    <li> $||\\ x^{(k+1)} - x^{(k)}\\ || < \\epsilon$ </li>\n",
    "    <li> $||\\ f(x^{(k+1)}) - f(x^{(k)})\\ || < \\epsilon$ </li>\n",
    "</ol>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Призван решить проблему обучения на очень большом наборе данных. Идея такого метода состоит в том, что градиент мы можем оценить по небольшому множеству примеров. Говоря конкретнее мы можем взять minibatch - небольшую выборку из обучающего множества размером не больше нескольких сотен и производить необходимые вычисления только на этой выборке \n",
    "\n",
    "<br>\n",
    "Преимущества такого подхода:\n",
    "<ul>\n",
    "    <li>\n",
    "    Усреднение градиента по нескольким переменным - представляет собо апроксимацию градиента по всему тренироввочному набору, причем чем больше пример в batche'e тем точнее приближение\n",
    "    </li><li>\n",
    "    Благодаря мини-батчам можно распараллелить вчисления\n",
    "    </li><li>\n",
    "    Использование разных частей данных помогает реже попадать в \"неверные\" минимумы\n",
    "    </li>\n",
    "</ul>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация по мини-батчам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация по мини-батчам - это нормализация входов по отдельности. А именно мы создаем слой который работает согласно следующему алгоритму для мини-батча $B = {x_1, ..., x_m}:\n",
    "<br>\n",
    "<ul>\n",
    "    <li>\n",
    "    Сначала мы вычисляем статистические величины, а именно среднее и дисперсию.\n",
    "    $$\\mu_B = \\frac{1}{m}\\Sigma^m_{i=1}x_i\\ \\ \\ \\sigma^2_B = \\frac{1}{m}\\Sigma^m_{i=1}(x_i-\\mu_B)^2$$\n",
    "    </li><li>\n",
    "    Затем мы нормализуем выходы\n",
    "    $$\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma^2_B + \\epsilon}}$$\n",
    "    </li><li>\n",
    "    И наонец, вычисляем результат\n",
    "    $$y_i = \\gamma x_i + \\beta$$\n",
    "</ul>\n",
    "Слой нормализация по мини-батчам можно поместить как до активационной функии (но после сумматорной, что очевидно), так и после активационной функции. \n",
    "<br>\n",
    "В итоге батч-нормализация:\n",
    "<ul>\n",
    "    <li>\n",
    "    Уменьшает ковариационный сдвиг во внутренних слоях нейронной сети и следовательно ускоряет обучение;\n",
    "    </li><li>\n",
    "    Является дифференцируемым преобразованием, то есть для обучения сети все так же можно применять метод обратного распространения ошибки;\n",
    "    </li><li>\n",
    "    Позволяет использовать большие шаги обучения, то есть позволяет не слишком аккуратно настраивать гиперпараметр шага;\n",
    "    </li><li>\n",
    "    Не производит явную декорреляцию входных данных для различных нейронов одного слоя.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регуляризация ##\n",
    "\n",
    "$$L1:\\;  J = J_0 + \\lambda\\Sigma_j\\Sigma_k\\Sigma_l|w_{jk}^{l}| $$\n",
    "\n",
    "$$L2:\\; J = J_0 + \\frac{\\lambda}{2}\\Sigma_j\\Sigma_k\\Sigma_l(w_{jk}^{l})^2 $$\n",
    "\n",
    "$$ J_0 - TSS; l - номер\\, слоя; k - из\\, какого\\, нейрона; j - в\\, какой\\, нейрон; \\lambda - гпиерпараметр$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>Здесь я хочу затронуть L1, L2 Regularization и Elastic Net (L1 + L2)\n",
    "Функции регуляризации - позволяют ввести контроль за весами, т.е. в функции ошибки (или целевой фунеции) мы теперь будем штрафовать сеть не только за не верное предсказание, но и за слишком большие или маленькие веса. Так регуляризация позволяет нам бороться с переобучением (overfitting). \n",
    "<br>К сожалению о преимуществах Elastic пока не знаю, но могу в кратце сказать о L1 и L2. В L1 к MSE(mean squared error) мы прибавляем абсолютную сумму всех весов, а в L2 сумму квадратов всех весов. \n",
    "Их основоное отличие друг от друга состоит в том, что L1 позволяет нам убрать не нужные функции (некоторые веса стремятся к 0), но она не дифференцируема. L2 сильнее штрафует за высокие веса, дифференциируема, однако не позволяет нам избавляться от ненужных нод. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropuout\n",
    "Тут же хочу сказать о дропауте. Идея его такова: для каждого нейрона (кроме очевидно выходных) будем устанавливать вероятность %%p%% c которой этот нейрон будет выброшен из сети. Таким образом дропаут позволяет усреднить модель -> полученная модель станет более устойчивой и снизится вероятность overfitting - а."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Можно воспользоваться предобучением без учителем, а именно алгоритмом contrastive divergence. Но этот алгоритм довольно таки не прост, и не популярен.\n",
    "<br>\n",
    "2) Xavier(Glorot) initialization - инициализация Ксавье, хороший вариант сети с симметричной функцией активации. Веса будем расрпределять равномерным(Uniform) распределением по следующему правилу: \n",
    "$$ \\omega_i \\approx U(-\\frac{\\sqrt{6}}{\\sqrt{n_{in} + n_{out}}} ; +\\frac{\\sqrt{6}}{\\sqrt{n_{in} + n_{out}}}) $$\n",
    "<br>\n",
    "3) He initialization - инициализация подходящая для линейный функций. Здесь распределение уже нормальное(Normal).\n",
    "$$ \\omega_i \\approx N(0, \\frac{\\sqrt{2}}{\\sqrt{n_{in}^{i}}}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод моментов: Ньютон, Нестеров и Гессе\n",
    "Что бы управлять learning_rate можно использовать линейное затухание $$\\eta = \\eta_0(1 - \\frac{t}{T}) $$\n",
    "Или экспоненциальное затухание $$\\eta = \\eta_0\\ e^{\\frac{-t}{T}} $$\n",
    "Однако это все не эффективно, так как вместо подбора одного параметра, нам нужно подбирать теперь три. Начальный $\\eta_0$, t - время(эпохи или количество минибатчей) с начала обучение, и Т - параметр, определяющий скорость уменьшения $\\eta$\n",
    "<br>\n",
    "На помощь спешат новые методы! \n",
    "<br>\n",
    "Метод испульсов - помогает ускорить градиентный спуск в нужном направлении и уменьшает его колебания, этот метод помогает выразить инерцию нашей точки.\n",
    "$$u_t = \\gamma u_{t-1} - \\eta\\nabla_{\\theta}E(\\theta)\\ \\ \\ \\ \\ \\theta = \\theta - u_t$$\n",
    "Здесть $\\gamma$ - параметр метода моментов, определяющий какую часть прошлого градиента мы хотим взять на текущем шаге, а на какую часть будем использовать новый градиент.\n",
    "<br>\n",
    "Метод Нестерова - усовершенствование предыдущего, позволяет \"смотреть\" на шаг вперед. В методе при расчете градиента используется значение функции ошибки в точке ($\\theta-\\gamma u_{t-1}$), т.е. веса изменяются по правилу:\n",
    "$$u_t = \\gamma u_{t-1} - \\eta\\nabla_\\theta E(\\theta - \\gamma u_{t-1})$$\n",
    "<br>\n",
    "Но можно еще лучше! Метод Ньютона, который к сожалению вычислить нереально(из-за матрицы Гессе) и это одна из нерешенных задачи машинного обучения :C\n",
    "$$ u = -(H(E(\\theta)))^{-1}\\nabla E(\\theta) $$\n",
    "Где H - матрица Гессе. Такой метод гораздо быстрее и автоматически настраивает параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификаторы #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перцептрон ###\n",
    "\n",
    "Перцептрон Розенблатта - линейная модель бинарной классификации. \n",
    "Перцептрон Румельхарта - многослойная модель. \n",
    "Основная идея перцептрона это его устройства, извиняюсь за тафтологию. Перцептрон внутренне состоит из сумматора (функции сумирующей входы в перцептрон) и активационной функции (тут мы в праве поступить вольно и выбрать удобную нам)\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x, \\omega, b) = \n",
    "\\begin{cases}\n",
    "    1 &\\text{,если $\\omega^T\\cdot x + b > 0$}\\\\\n",
    "    0,  &\\text{,если $\\omega^T\\cdot x + b \\le 0$}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "Сумматор.  $\\omega$ - вектор весов, $x$ - входной вектор и $b$ - bias (смещение)\n",
    "\n",
    "<br>Первый вход - фиктивный, на него всегда подается 1 и соответственно $\\omega [0]$ обозначает тогда bias.\n",
    "<br>Одиночный перцептрон имеет ряд ограничений, например он не может обучиться операции XOR. \n",
    "<br>В scikit есть перцептрон Румельхарта.Так же, в библиотеке указано что перцептрон есть частный случай стохастического градиентного спуска с констаным learnin_rate и без штрафов веса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression ### \n",
    "\n",
    "Это линейный КЛАССИФИКАТОР. Не имеет ничего общего с регрессией, но назван так наверное из-за того что использует в себе понятие линейной регрессии. Лучше всего применяется с сигмоидальной функцией активации и перекрестной \n",
    "энтропией, т.к. на выходе сети мы ожидаем поулчить вероятность того принадлежит ли объект классу (ну или не объект) или для множественных выходов, можем определить к какому классу из перечислинных больше всего относится объект( на какой класс больше всего похож, если можно так выразиться) \n",
    "<br>Имеет свои ограничения на применения: линейная зависимость переменных; нормальное распределение остатков; постоянная изменчивость остатков (гомоскедастичность) и т.д. (из стастистики)\n",
    "<br>В самом scikit имеет интересные параметры, такие как использование регуляризации и выбор одной из нескольких реализаций.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier ###\n",
    "\n",
    "Ну по русски если там можно выразиться стохастический градиентный классификатор. \n",
    "<br>Начну с градиентного спуска, а именно со стохастического градиентного спуска (далее просто SGD). Почему именно SGD, да потому что затратно будет считать GD по всем переменным, да и излишняя точность нам ни к чему. Поэтому мы и будем считать градиент \"случайно\". \n",
    "Используя градиент мы будет корректировать веса, ведь, -SGD это вектор направленный в сторону наибольшего убывания функции J, а её минимум нам и нужен (ну очевидно что бы ошибка была минимальна)\n",
    "<br>И про алгоритм обратного распространения ошибки -> тут все тоже очевидно, во время обратного прохода мы будем корректировать веса исходия из значения ошибки и предыдущих весов. \n",
    "<br>Так вот, в основе SGDClassifier лежат линейные модели, например LogisticRegression , к которой применяется тренировка методом стохастического градиентного спуска.\n",
    "<br>В scikit доступны нексколько моделей перечислять не буду пожалуй."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis ###\n",
    "\n",
    "Классификатор основанный на формуле Байеса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

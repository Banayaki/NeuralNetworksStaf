{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PassiveAggressiveClassifier,\n",
    "               <br>SGDClassifier,\n",
    "               <br>Perceptron+,\n",
    "               <br>DecisionTreeClassifier,\n",
    "               <br>RandomForestClassifier,\n",
    "               <br>LogisticRegression+,\n",
    "               <br>MLPClassifier,\n",
    "               <br>KNeighborsClassifier,\n",
    "               <br>SVC,\n",
    "               <br>GaussianNB,\n",
    "               <br>ExtraTreeClassifier,\n",
    "               <br>LinearSVC,\n",
    "               <br>GaussianProcessClassifier,\n",
    "<br>GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основы основ #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции активации ##\n",
    "<img src=\"ActivationFunc.png\">\n",
    "<br>Теперь кратко об их основых преимуществах. \n",
    "<br>Сигмоида. Преимуществ по сравнению с другими вариантами не так много. Старенькая функция активации.\n",
    "<br>Гиперболический тангенс. Чуть лучше чем сигмоида благодаря тому, что в нуле имеет более крутой наклон. В остальном все те же минусы: тяжело считать производную и не понимает 'силу активации'\n",
    "<br>Функция Хевисайда. Тут даже сказать нечего, производная равна нулю, значит и градиент равен нулю, все плохо.\n",
    "<br>Soft plus. Интеграл взятый от сигмоиды, т.к. сигмоида не учитывет слишком высокую силу активацию, решили найти бесконечный ряд из суммы сигмоид, в итоге получили функцию soft plus, лучше предыдующих вариантов тем, что реагирует на большие веса\n",
    "<br>ReLU (rectified linear units) - улучшенный линейный нейрон. Самый хороший вариант для просто нейронной сети. Является апроксимацией soft plus. Маленькие затраты на вычисление функции и градиента, что несомненно плюс, так же отличает сильную активацию от не очень сильной. \n",
    "<br>PReLU (parametrezied ReLU). Тут у нас появляется параметр, благодаря которому мы имеем немного другую производную при малых x. \n",
    "<br>Про ELU сказать особо нечего.\n",
    "\n",
    "<br>Так что все стандартные алгоритмы стоит пробовать на ReLU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1 + numpy.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1. - sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return numpy.tanh(x)\n",
    "\n",
    "def dtanh(x):\n",
    "    return 1. - tanh(x) ** 2\n",
    "\n",
    "def ReLU(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def dReLU(x):\n",
    "    return 1. * (x > 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Целевые функции (функции ошибок) ##\n",
    "\n",
    "#### Среднеквадратичная функция (MSE)\n",
    "$$ MSE = \\frac{1}{2}\\Sigma^{n}_{i = 1}(a_i - y_i)^2 $$\n",
    "Особенности:\n",
    "<li>Зависимость от производной функции активации\n",
    "    \n",
    "#### Перекрестная энтропия \n",
    "$$Cross-Entropy\\, loss: J = - \\frac{1}{n}\\Sigma_{i=1}^{n}\\Sigma_{j=1}^{m}\\Big(y_{j}^{(i)}\\ln a_{j}^{(i)} + (1 - y_{j}^{(i)})\\ln(1 - a_{j}^{(i)})\\Big) $$\n",
    "Особенности:\n",
    "<li>Высокая скорость сходимости алгоритма обучения\n",
    "\n",
    "$$ i - номер\\, эксперемента(испытания); j - номер\\, выхода $$\n",
    "\n",
    "#### Правдоподобие (Log-likelihood)\n",
    "$$ E = - \\ln a^L_i $$\n",
    "\n",
    "\n",
    "#### Выбор типа функции потерь\n",
    "\n",
    "###### Задача регрессии\n",
    "функция активации в выходном слое: линейная\n",
    "<br>функция потерь: MSE или Cross Entropy\n",
    "\n",
    "##### Задача классификации\n",
    "функция активации в выходном слое: сигмоида\n",
    "функция потерь: Cross Entropy или Правдоподобие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регуляризация ##\n",
    "\n",
    "$$L1:\\;  J = J_0 + \\lambda\\Sigma_j\\Sigma_k\\Sigma_l|w_{jk}^{l}| $$\n",
    "\n",
    "$$L2:\\; J = J_0 + \\frac{\\lambda}{2}\\Sigma_j\\Sigma_k\\Sigma_l(w_{jk}^{l})^2 $$\n",
    "\n",
    "$$ J_0 - TSS; l - номер\\, слоя; k - из\\, какого\\, нейрона; j - в\\, какой\\, нейрон; \\lambda - гпиерпараметр$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>Здесь я хочу затронуть L1, L2 Regularization и Elastic Net (L1 + L2)\n",
    "Функции регуляризации - позволяют ввести контроль за весами, т.е. в функции ошибки (или целевой фунеции) мы теперь будем штрафовать сеть не только за не верное предсказание, но и за слишком большие или маленькие веса. Так регуляризация позволяет нам бороться с переобучением (overfitting). \n",
    "<br>К сожалению о преимуществах Elastic пока не знаю, но могу в кратце сказать о L1 и L2. В L1 к MSE(mean squared error) мы прибавляем абсолютную сумму всех весов, а в L2 сумму квадратов всех весов. \n",
    "Их основоное отличие друг от друга состоит в том, что L1 позволяет нам убрать не нужные функции (некоторые веса стремятся к 0), но она не дифференцируема. L2 сильнее штрафует за высокие веса, дифференциируема, однако не позволяет нам избавляться от ненужных нод. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификаторы #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перцептрон ###\n",
    "\n",
    "Перцептрон Розенблатта - линейная модель бинарной классификации. \n",
    "Перцептрон Румельхарта - многослойная модель. \n",
    "Основная идея перцептрона это его устройства, извиняюсь за тафтологию. Перцептрон внутренне состоит из сумматора (функции сумирующей входы в перцептрон) и активационной функции (тут мы в праве поступить вольно и выбрать удобную нам)\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x, \\omega, b) = \n",
    "\\begin{cases}\n",
    "    1 &\\text{,если $\\omega^T\\cdot x + b > 0$}\\\\\n",
    "    0,  &\\text{,если $\\omega^T\\cdot x + b \\le 0$}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "Сумматор.  $\\omega$ - вектор весов, $x$ - входной вектор и $b$ - bias (смещение)\n",
    "\n",
    "<br>Первый вход - фиктивный, на него всегда подается 1 и соответственно $\\omega [0]$ обозначает тогда bias.\n",
    "<br>Одиночный перцептрон имеет ряд ограничений, например он не может обучиться операции XOR. \n",
    "<br>В scikit есть перцептрон Румельхарта.Так же, в библиотеке указано что перцептрон есть частный случай стохастического градиентного спуска с констаным learnin_rate и без штрафов веса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression ### \n",
    "\n",
    "Это линейный КЛАССИФИКАТОР. Не имеет ничего общего с регрессией, но назван так наверное из-за того что использует в себе понятие линейной регрессии. Лучше всего применяется с сигмоидальной функцией активации и перекрестной \n",
    "энтропией, т.к. на выходе сети мы ожидаем поулчить вероятность того принадлежит ли объект классу (ну или не объект) или для множественных выходов, можем определить к какому классу из перечислинных больше всего относится объект( на какой класс больше всего похож, если можно так выразиться) \n",
    "<br>Имеет свои ограничения на применения: линейная зависимость переменных; нормальное распределение остатков; постоянная изменчивость остатков (гомоскедастичность) и т.д. (из стастистики)\n",
    "<br>В самом scikit имеет интересные параметры, такие как использование регуляризации и выбор одной из нескольких реализаций.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier ##\n",
    "\n",
    "Ну по русски если там можно выразиться стохастический градиентный классификатор. \n",
    "<br>Начну с градиентного спуска, а именно со стохастического градиентного спуска (далее просто SGD). Почему именно SGD, да потому что затратно будет считать GD по всем переменным, да и излишняя точность нам ни к чему. Поэтому мы и будем считать градиент \"случайно\". \n",
    "Используя градиент мы будет корректировать веса, ведь, -SGD это вектор направленный в сторону наибольшего убывания функции J, а её минимум нам и нужен (ну очевидно что бы ошибка была минимальна)\n",
    "<br>И про алгоритм обратного распространения ошибки -> тут все тоже очевидно, во время обратного прохода мы будем корректировать веса исходия из значения ошибки и предыдущих весов. \n",
    "<br>Так вот, в основе SGDClassifier лежат линейные модели, например LogisticRegression , к которой применяется тренировка методом стохастического градиентного спуска.\n",
    "<br>В scikit доступны нексколько моделей перечислять не буду пожалуй."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis ###\n",
    "\n",
    "Классификатор основанный на формуле Байеса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
